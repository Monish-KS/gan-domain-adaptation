# Domain Adaptation with GAN-based Data Augmentation

A deep learning research project exploring domain adaptation techniques for low-resource scenarios, comparing GAN-based augmentation against traditional methods when transferring from MNIST (source domain) to SVHN (target domain).

## Table of Contents

- [Overview](#overview)
- [Project Architecture](#project-architecture)
- [Features](#features)
- [Requirements](#requirements)
- [Installation](#installation)
- [Quick Start](#quick-start)
- [Running Experiments](#running-experiments)
  - [Training a GAN](#training-a-gan)
  - [Running Individual Experiments](#running-individual-experiments)
  - [Running All Experiments](#running-all-experiments)
- [Web Interface](#web-interface)
- [Project Structure](#project-structure)
- [Understanding Results](#understanding-results)
- [Visualization with TensorBoard](#visualization-with-tensorboard)
- [Troubleshooting](#troubleshooting)

## Overview

This project investigates domain adaptation strategies for image classification in low-resource scenarios. The core research question is: **How can we effectively transfer knowledge from a source domain (MNIST handwritten digits) to a target domain (SVHN street numbers) when we have very limited labeled data in the target domain?**

### What It Does

1. **Pre-trains** a CNN classifier on MNIST (source domain with abundant data)
2. **Compares four domain adaptation strategies** on SVHN (target domain with limited data):
   - **Source Only**: Direct evaluation without fine-tuning
   - **Fine-Tune**: Direct fine-tuning on limited SVHN data
   - **Traditional Augmentation**: Fine-tuning with standard augmentation (rotation, flipping, etc.)
   - **GAN Augmentation**: Fine-tuning with synthetic images generated by a Conditional DCGAN
3. **Evaluates** performance across different data scarcity levels (10, 100, 1000 samples)
4. **Visualizes** results through a web interface with interactive charts and model predictions

## Project Architecture

```
┌─────────────────────────────────────────────────────────────┐
│                     DOMAIN ADAPTATION PIPELINE               │
├─────────────────────────────────────────────────────────────┤
│                                                               │
│  1. PRE-TRAINING (Source Domain)                             │
│     ┌──────────┐                                             │
│     │  MNIST   │──► CNN Classifier ──► Pre-trained Model     │
│     │ (60,000) │                                             │
│     └──────────┘                                             │
│                                                               │
│  2. GAN TRAINING (Target Domain - Low Resource)              │
│     ┌─────────────┐                                          │
│     │ SVHN (N=10, │──► Conditional DCGAN ──► Generator       │
│     │  100, 1000) │    (Generator + Discriminator)           │
│     └─────────────┘                                          │
│                                                               │
│  3. DOMAIN ADAPTATION SCENARIOS                              │
│     ┌────────────────┐                                       │
│     │ Source Only    │──► Evaluate directly on SVHN test     │
│     │ Fine-Tune      │──► Train on N real SVHN samples       │
│     │ Traditional Aug│──► Train on N + augmented samples     │
│     │ GAN Aug        │──► Train on N real + synthetic images │
│     └────────────────┘                                       │
│                                                               │
│  4. EVALUATION                                               │
│     ┌────────────┐                                           │
│     │ SVHN Test  │──► Accuracy, Classification Report        │
│     │ (~26,000)  │                                           │
│     └────────────┘                                           │
└─────────────────────────────────────────────────────────────┘
```

## Features

- **Multiple Domain Adaptation Strategies**: Compare 4 different approaches
- **GAN-based Data Augmentation**: Conditional DCGAN for generating synthetic training data
- **Systematic Experimentation**: Automated experiment running with organized result storage
- **Comprehensive Logging**: TensorBoard integration for tracking training metrics
- **Web Interface**: Interactive dashboard for result visualization and model inference
- **Reproducible Research**: Structured experiment organization with JSON result files

## Requirements

### Core Dependencies

- Python 3.8+
- PyTorch 2.0.1+
- torchvision 0.15.2+
- scikit-learn 1.3.0+
- numpy 1.24.3+
- Pillow 10.0.0+

### Web Interface Dependencies

**Backend:**
- Flask 2.3.2
- Flask-Cors 4.0.0

**Frontend:**
- Node.js 14+
- React 18.2.0
- chart.js 4.4.0
- react-chartjs-2 5.2.0

## Installation

### 1. Clone the Repository

```bash
git clone <your-repository-url>
cd DLProject
```

### 2. Set Up Python Environment

It's recommended to use a virtual environment:

```bash
# Create virtual environment
python -m venv venv

# Activate virtual environment
# On Windows:
venv\Scripts\activate
# On Linux/Mac:
source venv/bin/activate
```

### 3. Install Python Dependencies

```bash
# Install core dependencies
pip install torch==2.0.1 torchvision==0.15.2
pip install scikit-learn==1.3.0 numpy==1.24.3 Pillow==10.0.0

# Install web interface backend dependencies (optional)
pip install Flask==2.3.2 Flask-Cors==4.0.0
```

Or create a `requirements.txt` file in the root directory:

```txt
torch==2.0.1
torchvision==0.15.2
scikit-learn==1.3.0
numpy==1.24.3
Pillow==10.0.0
Flask==2.3.2
Flask-Cors==4.0.0
```

Then install:

```bash
pip install -r requirements.txt
```

### 4. Install Web Interface Frontend Dependencies (Optional)

If you want to use the web interface:

```bash
cd web_interface/frontend
npm install
cd ../..
```

### 5. Download Datasets

The datasets (MNIST and SVHN) will be automatically downloaded when you first run the experiments. Make sure you have:
- ~500 MB of free disk space for datasets
- Stable internet connection for initial download

## Quick Start

### Run a Single Experiment

To quickly test the setup, run a single experiment with 100 SVHN samples using GAN augmentation:

```bash
# Step 1: Train the GAN
python train_gan.py --n_samples 100 --epochs 100 --output_dir outputs

# Step 2: Run the main experiment
python main_experiment.py --scenario gan_aug --n_samples 100 --output_dir experiments/quick_test --gan_model_base_dir outputs
```

This will:
1. Pre-train a classifier on MNIST (first run only, cached afterward)
2. Train a GAN on 100 SVHN samples
3. Generate synthetic images
4. Fine-tune the classifier using real + synthetic data
5. Evaluate on the SVHN test set

Expected output: Accuracy around 20-40% (better than source-only baseline)

## Running Experiments

### Training a GAN

Before running GAN augmentation experiments, you need to train a GAN for each data size:

```bash
# Train GAN with 10 samples
python train_gan.py --n_samples 10 --epochs 100 --output_dir outputs

# Train GAN with 100 samples
python train_gan.py --n_samples 100 --epochs 100 --output_dir outputs

# Train GAN with 1000 samples
python train_gan.py --n_samples 1000 --epochs 100 --output_dir outputs
```

**Arguments:**
- `--n_samples`: Number of low-resource SVHN samples to train the GAN (default: 100)
- `--epochs`: Number of training epochs (default: 100)
- `--nz`: Latent vector size (default: 100)
- `--lr`: Learning rate (default: 0.0002)
- `--batch_size`: Batch size (default: 64)
- `--output_dir`: Directory to save GAN outputs (default: "outputs")

Generated images will be saved in `<output_dir>/gan_images/` every 10 epochs.

### Running Individual Experiments

Run a specific scenario with a given number of samples:

```bash
# Source only (no fine-tuning)
python main_experiment.py --scenario source_only --n_samples 100 --output_dir experiments/exp_source_only

# Fine-tuning
python main_experiment.py --scenario fine_tune --n_samples 100 --output_dir experiments/exp_fine_tune

# Traditional augmentation
python main_experiment.py --scenario traditional_aug --n_samples 100 --output_dir experiments/exp_trad_aug

# GAN augmentation (requires pre-trained GAN)
python main_experiment.py --scenario gan_aug --n_samples 100 --output_dir experiments/exp_gan_aug --gan_model_base_dir outputs
```

**Key Arguments:**
- `--scenario`: Choose from `source_only`, `fine_tune`, `traditional_aug`, `gan_aug`
- `--n_samples`: Number of low-resource SVHN samples (10, 100, 1000, etc.)
- `--output_dir`: Directory to save experiment results
- `--gan_model_base_dir`: Directory where GAN models are stored (only for `gan_aug`)
- `--classifier_epochs_mnist`: Epochs for MNIST pre-training (default: 5)
- `--classifier_epochs_finetune`: Epochs for SVHN fine-tuning (default: 20)
- `--batch_size`: Batch size (default: 64)
- `--classifier_lr`: Learning rate (default: 0.001)

### Running All Experiments

To run a comprehensive suite of experiments comparing all scenarios across multiple data sizes:

```bash
python run_all_experiments.py
```

This script will:
1. Create a timestamped experiment directory
2. For each configuration:
   - Train a GAN (if needed for `gan_aug` scenario)
   - Run the main experiment
   - Save all results in organized subdirectories
3. Generate results for scenarios: `source_only`, `fine_tune`, `traditional_aug`, `gan_aug`
4. Test with sample sizes: N=10, N=100, N=1000

**Note:** Running all experiments can take several hours, depending on your hardware (GPU recommended).

Results will be saved in: `experiments/<timestamp>_N<sample_size>/`

## Web Interface

The web interface provides an interactive dashboard to:
- View experiment results and metrics
- Compare performance across scenarios
- Visualize GAN-generated images
- Perform real-time predictions with trained models

### Starting the Web Interface

#### 1. Start the Backend Server

```bash
cd web_interface/backend
python app.py
```

The backend API will start on `http://localhost:5000`

#### 2. Start the Frontend Development Server

In a new terminal:

```bash
cd web_interface/frontend
npm start
```

The web interface will open automatically at `http://localhost:3000`

### Using the Web Interface

1. **Dashboard**: View summary of all experiments with accuracy comparisons
2. **Experiment Details**: Click on any experiment to see detailed metrics and classification reports
3. **GAN Gallery**: Browse generated images from different training epochs
4. **Interactive Prediction**: Upload an SVHN digit image to get real-time predictions

## Project Structure

```
DLProject/
├── data/                          # Datasets (auto-downloaded)
│   ├── MNIST/                     # MNIST dataset
│   └── train_32x32.mat           # SVHN training data
│   └── test_32x32.mat            # SVHN test data
│
├── experiments/                   # Experiment results (timestamped directories)
│   └── <timestamp>_N<samples>/
│       ├── exp_source_only_N<X>/
│       ├── exp_fine_tune_N<X>/
│       ├── exp_traditional_aug_N<X>/
│       ├── exp_gan_aug_N<X>/
│       ├── checkpoints/          # Saved model weights (.pth files)
│       ├── tensorboard_logs/     # TensorBoard logs
│       ├── gan_images/           # Generated images
│       └── results/              # JSON result files
│
├── outputs/                       # Default output directory
│   ├── checkpoints/
│   │   ├── classifier_mnist_pretrained.pth
│   │   └── gan_generator_n<X>.pth
│   └── gan_images/
│
├── web_interface/
│   ├── backend/                  # Flask API server
│   │   ├── app.py               # Main Flask application
│   │   ├── models.py            # Model definitions
│   │   ├── data_loader.py       # Data loading utilities
│   │   └── requirements.txt     # Backend dependencies
│   └── frontend/                 # React web application
│       ├── src/
│       │   ├── components/      # React components
│       │   └── App.js
│       └── package.json
│
├── models.py                     # Neural network architectures
├── data_loader.py               # Dataset loading and preprocessing
├── train_gan.py                 # GAN training script
├── main_experiment.py           # Main experiment orchestration
├── run_all_experiments.py       # Batch experiment runner
├── utils.py                     # Utility functions
├── domain_adaptation_experiment.ipynb  # Jupyter notebook for exploration
└── README.md                    # This file
```

## Understanding Results

### Result Files

Each experiment generates a JSON file with the following structure:

```json
{
  "scenario": "gan_aug",
  "n_samples": 100,
  "final_accuracy": 0.3542,
  "classification_report": "...",
  "timestamp": "2025-10-22T10:30:45",
  "log_dir": "experiments/.../tensorboard_logs/..."
}
```

### Interpreting Results

- **Source Only**: Baseline performance (typically 10-20% accuracy)
- **Fine-Tune**: Shows improvement from target domain adaptation
- **Traditional Aug**: Benefits from standard augmentation techniques
- **GAN Aug**: Should show best performance, especially with very limited data (N=10, N=100)

### Expected Performance Ranges

| Scenario | N=10 | N=100 | N=1000 |
|----------|------|-------|--------|
| Source Only | 10-15% | 10-15% | 10-15% |
| Fine-Tune | 15-25% | 25-40% | 50-70% |
| Traditional Aug | 20-30% | 30-45% | 55-75% |
| GAN Aug | 25-35% | 35-50% | 60-80% |

*Note: These are approximate ranges. Actual results may vary based on randomness and hyperparameters.*

## Visualization with TensorBoard

Monitor training progress in real-time:

```bash
# View experiment results
tensorboard --logdir experiments/<timestamp>_N<samples>/tensorboard_logs

# View GAN training
tensorboard --logdir outputs/tensorboard_logs
```

Then open `http://localhost:6006` in your browser.

**What you'll see:**
- Training and validation accuracy curves
- Loss curves for classifier, generator, and discriminator
- Generated image samples at different epochs
- Comparison across different runs

## Troubleshooting

### Common Issues

**1. CUDA Out of Memory**

If you get GPU memory errors, reduce the batch size:

```bash
python main_experiment.py --scenario gan_aug --n_samples 100 --batch_size 32 --output_dir experiments/test
```

**2. Dataset Download Fails**

If automatic download fails, manually download:
- MNIST: Usually downloads automatically via torchvision
- SVHN: Download from http://ufldl.stanford.edu/housenumbers/
  - `train_32x32.mat`
  - `test_32x32.mat`
  
Place them in the `data/` directory.

**3. GAN Model Not Found**

Ensure you've trained the GAN before running `gan_aug` experiments:

```bash
python train_gan.py --n_samples 100 --epochs 100 --output_dir outputs
```

Make sure to specify the correct `--gan_model_base_dir` when running experiments.

**4. Web Interface Connection Issues**

If frontend can't connect to backend:
- Ensure Flask backend is running on port 5000
- Check for CORS errors in browser console
- Verify Flask-Cors is installed: `pip install Flask-Cors`

**5. Low Accuracy Results**

This is expected for domain adaptation with very limited data:
- Source-only should give ~10-15% (random is 10%)
- With N=10 samples, even GAN augmentation may only reach 25-35%
- With N=1000 samples, you should see 60-80% with GAN augmentation

### Getting Help

For additional help:
1. Check the inline documentation in each Python file
2. Review the Jupyter notebook `domain_adaptation_experiment.ipynb` for detailed exploration
3. Examine TensorBoard logs to diagnose training issues
4. Ensure all dependencies are correctly installed with correct versions

## Citation

If you use this code for your research, please cite:

```bibtex
@misc{domain_adaptation_gan,
  author = {Monish K S, Nitish S},
  title = {Domain Adaptation with GAN-based Data Augmentation},
  year = {2025},
  publisher = {GitHub},
  url = {https://github.com/Monish-KS/gan-domain-adaptation}
}
```

## License

This project is provided for educational and research purposes.

## Acknowledgments

- MNIST dataset: Yann LeCun et al.
- SVHN dataset: Yuval Netzer et al.
- PyTorch framework: Facebook AI Research

